{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d3f0235",
   "metadata": {},
   "source": [
    "**Credits**: Initial code by Sepideh Adamiat and Thijs van de Laar, re-implemented by Dmitry Bagaev in RxInfer.jl. The initial example is taken from ForneyLab.jl and the Thijs' PhD thesis: https://research.tue.nl/en/publications/automated-design-of-bayesian-signal-processing-algorithms\n",
    "\n",
    "**NOTE**: This notebook is written in Julia. Julia programming language compiles code on-the-fly and first executation is always very slow due to initial compilation. Sometimes the initial compilation takes several minutes before actual execution of the code (especially GLMakie...). I suggest click `Cell` -> `Run all` and grab a cup of coffee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf58d5fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m  Activating\u001b[22m\u001b[39m project at `~/Projects/BIASlab/Verses`\n"
     ]
    }
   ],
   "source": [
    "# This cell takes a lot of time for the very first time, especially GLMakie, for interactive plotting\n",
    "# Installs all necessary packages\n",
    "import Pkg; Pkg.activate(\".\"); Pkg.instantiate();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "17cc1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RxInfer, Rocket, LinearAlgebra, GLMakie, DataStructures\n",
    "\n",
    "import ReactiveMP: getrecent, messageout, update!\n",
    "import Rocket: subscribe!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bafba83",
   "metadata": {},
   "source": [
    "**Note**: This notebook uses 2 reactive libraries: `Observables.jl` and `Rocket.jl`. `Rocket.jl` has been developed in BIASlab and is highly efficient. `GLMakie.jl`, however, uses `Observables.jl`, because `Rocket.jl` did not exist at the moment. Please, do not confuse `Rocket.jl` observables/actors/subjects and `Observables.jl` observables. The functionality of the `Observables.jl` is very very simple, while `Rocket.jl` is a comprehensive self-contained reactive extensions framework with a lot of extra functionality (and also faster :))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7aabea8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "shift (generic function with 2 methods)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some utility functionality\n",
    "# Returns a variable argument function, that shifts a vector and put a new value at the end\n",
    "function shift(vector, value)\n",
    "    return (args...) -> begin \n",
    "        @inbounds for i in firstindex(vector):lastindex(vector)-1\n",
    "            vector[i] = vector[i + 1]\n",
    "        end\n",
    "        vector[end] = value[]\n",
    "        return vector\n",
    "    end\n",
    "end\n",
    "\n",
    "# These are utility functions and are not interesting, skip for now\n",
    "function shift(vector, subject::AbstractSubject)\n",
    "    return (_) -> begin \n",
    "        subscribe!(subject |> take(1), (value) -> shift(vector, value)())\n",
    "        return vector\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a09a0b",
   "metadata": {},
   "source": [
    "# Simulation preparation\n",
    "\n",
    "The very first step in our simulation would be to prepate the pendulum environment that we can play with. Our environment will consist of multiple global parameters, which we will change interactively later on. The parameters are implemented in the `WorldParameters` structure which will be created and shared globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32934797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pendulum_bob_position (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Our beautiful world parameters\n",
    "Base.@kwdef mutable struct PendulumWorldParameters\n",
    "    bob_mass           :: Float64 = 0.2 # grams\n",
    "    rod_length         :: Float64 = 0.2 # cm\n",
    "    friction           :: Float64 = 0.2\n",
    "    gravity            :: Float64 = 9.81\n",
    "    engine_max_power   :: Float64 = 1.0\n",
    "    observations_noise :: Float64 = 1e-6\n",
    "    worlds_clock_Δt    :: Float64 = 1 / 30\n",
    "end\n",
    "\n",
    "# Its better not to rerun this cell as it defines the `const` global variable\n",
    "const parameters = PendulumWorldParameters();\n",
    "\n",
    "function pendulum_bob_position(angle)\n",
    "    return Point2f(parameters.rod_length * sin(angle), -parameters.rod_length * cos(angle))\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f304c9a",
   "metadata": {},
   "source": [
    "## State transition functions\n",
    "\n",
    "The pendulum differential equations can be represented as a special case of a non-linear state-transition probabilistic model with the following state transition function. In the current simulation we assume that the dynamical model of the world is known. In our simulation we also want to ensure that the engine connected to the pendulum has a limited power. We model such a restriction with the `tanh` function, because its a function with a known inverse mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b2c311f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state_transition (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# These functions restrict the engine power to a maximum value of `engine_max_power`\n",
    "function restrict_engine_power(action) \n",
    "    return parameters.engine_max_power * tanh(action / parameters.engine_max_power)\n",
    "end\n",
    "\n",
    "function state_transition(previous_state, action) \n",
    "    # Transition function modeling transition due to gravity, friction and engine control\n",
    "    (θ, θ̇) = previous_state\n",
    "    θ̈ = 1 / (parameters.bob_mass * parameters.rod_length ^ 2) * \n",
    "        (-parameters.bob_mass * parameters.gravity * parameters.rod_length * sin(θ) - \n",
    "            parameters.friction * θ̇ .+ restrict_engine_power(action))\n",
    "    Δs = (θ̇, θ̈)\n",
    "    next_state = previous_state .+  Δs .* parameters.worlds_clock_Δt\n",
    "    return next_state\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a91c6b5",
   "metadata": {},
   "source": [
    "## The implementation of the WORLD\n",
    "\n",
    "Only one single pendulum exists in our simulated world, which makes our task a bit easier. We implement the world in the `PendulumWorld` structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "517c88c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "register_next_action (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEHOLD THE IMPLEMENTATION OF THE WHOLE WORLD\n",
    "Base.@kwdef mutable struct PendulumWorld\n",
    "    pendulum_hidden_state :: Tuple{Float64, Float64} = (0.0, 0.0)\n",
    "    next_registered_action  = 0.0\n",
    "    noise_free_observations = RecentSubject(Float64)\n",
    "    noisy_observations      = RecentSubject(Float64)\n",
    "    ticks                   = Subject(Bool)\n",
    "    observations_history    = CircularBuffer(30)\n",
    "    actions_history         = CircularBuffer(30)\n",
    "end\n",
    "\n",
    "# `tick` function is used to move the state of the world further and is independed from any agent\n",
    "# An agent can only `register` a new action in between with the `register_next_action`\n",
    "function tick(world::PendulumWorld)\n",
    "    next_hidden_state = state_transition(world.pendulum_hidden_state, world.next_registered_action)\n",
    "    stochastic_state  = rand(MvNormalMeanPrecision(collect(next_hidden_state), 1e10 * diageye(2)))\n",
    "            \n",
    "    noise_free_observation = first(stochastic_state)\n",
    "    noisy_observation      = rand(NormalMeanVariance(noise_free_observation, parameters.observations_noise))\n",
    "        \n",
    "    # Save history for debugging and plotting\n",
    "    push!(world.actions_history, restrict_engine_power(world.next_registered_action))\n",
    "    push!(world.observations_history, noisy_observation)\n",
    "    \n",
    "    world.next_registered_action = 0.0\n",
    "    world.pendulum_hidden_state = (stochastic_state[1], stochastic_state[2])\n",
    "    \n",
    "    # Fire tick events \n",
    "    next!(world.noise_free_observations, noise_free_observation)\n",
    "    next!(world.noisy_observations, noisy_observation)\n",
    "    next!(world.ticks, true)\n",
    "end\n",
    "\n",
    "function register_next_action(world::PendulumWorld, action)\n",
    "    world.next_registered_action = action\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867fe42b",
   "metadata": {},
   "source": [
    "## The implementation of the AGENT\n",
    "\n",
    "To implement the pendulum controlling agent we define the probabilistic model of the world with the `@model` macro from **RxInfer**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3af4a730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pendulum_constraints (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model function pendulum(T)\n",
    "    # Internal model parameters\n",
    "    P = constvar(1e10 * diageye(2)) # Transition precision\n",
    "    C = constvar([1.0, 0.0])        # Observation matrix\n",
    "    \n",
    "    # Previous state prior\n",
    "    m_s_t_min = datavar(Vector{Float64})\n",
    "    v_s_t_min = datavar(Matrix{Float64})\n",
    "    \n",
    "    # Previous action prior\n",
    "    m_u_t_min = datavar(Float64)\n",
    "    v_u_t_min = datavar(Float64)\n",
    "    \n",
    "    # Current observation\n",
    "    x_t = datavar(Float64)\n",
    "    \n",
    "    # Future control priors\n",
    "    m_u = datavar(Float64, T)\n",
    "    v_u = datavar(Float64, T)\n",
    "    \n",
    "    # Future goal priors\n",
    "    m_x = datavar(Float64, T)\n",
    "    v_x = datavar(Float64, T)\n",
    "    \n",
    "    u   = randomvar(T) # Future actions\n",
    "    u_s = randomvar(T) # Future deterministic states\n",
    "    s   = randomvar(T) # Future states with uncertainty\n",
    "    x   = randomvar(T) # Future observations\n",
    "    \n",
    "    n_alpha = datavar(Float64)\n",
    "    n_theta = datavar(Float64)\n",
    "    n ~ InverseGamma(n_alpha, n_theta)\n",
    "\n",
    "    s_t_min ~ MvNormal(mean = m_s_t_min, covariance = v_s_t_min) # Prior for previous state\n",
    "    u_t_min ~ Normal(mean = m_u_t_min, variance = v_u_t_min)   # Prior for previous action\n",
    "    u_s_min ~ state_transition(s_t_min, u_t_min)          # Deterministic state transition function\n",
    "    s_t     ~ MvNormal(mean = u_s_min, precision = P) # Transition uncertainty\n",
    "    x_t     ~ Normal(mean = dot(C, s_t), variance = n)   # Observational function\n",
    "    \n",
    "    s_k_min = s_t\n",
    "    \n",
    "    for k in 1:T\n",
    "        u[k]    ~ Normal(mean = m_u[k], variance = v_u[k])\n",
    "        u_s[k]  ~ state_transition(s_k_min, u[k])\n",
    "        s[k]    ~ MvNormal(mean = u_s[k], precision = P)\n",
    "        x[k]    ~ Normal(mean = dot(C, s[k]), variance = n)\n",
    "        x[k]    ~ Normal(mean = m_x[k], variance = v_x[k]) \n",
    "        s_k_min = s[k]\n",
    "    end\n",
    "\n",
    "end\n",
    "\n",
    "@meta function pendulum_meta()\n",
    "    state_transition() -> DeltaMeta(method = Linearization())\n",
    "end\n",
    "\n",
    "@constraints function pendulum_constraints()\n",
    "    q(s_t, x, s, u, n) = q(x, s, u, s_t)q(n)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd49ccc5",
   "metadata": {},
   "source": [
    "Next step is to connect the agent with the outside world, for that purpose we create a special `SuperSmartRxInferAgent` structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa77f501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stop! (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mutable struct SuperSmartRxInferAgent\n",
    "    datastream               :: AbstractSubscribable\n",
    "    rxinfer_engine           :: Union{Nothing, RxInferenceEngine}\n",
    "    mean_control_priors      :: Vector{Float64}\n",
    "    var_control_priors       :: Vector{Float64}\n",
    "    mean_goal_priors         :: Vector{Float64}\n",
    "    var_goal_priors          :: Vector{Float64}\n",
    "    mean_current_state_prior :: Vector{Float64}\n",
    "    cov_current_state_prior  :: Matrix{Float64}\n",
    "    subscriptions            :: Vector{Teardown}\n",
    "    execution_time           :: AbstractSubject\n",
    "    vmp_iterations           :: AbstractSubject\n",
    "    recent_action            :: AbstractSubject\n",
    "    free_energy              :: AbstractSubject\n",
    "    the_goal_in_radians      :: AbstractSubject\n",
    "    the_goal_variance        :: AbstractSubject\n",
    "    \n",
    "    function SuperSmartRxInferAgent(T::Int, datastream::AbstractSubscribable)\n",
    "        mean_control_priors = zeros(T)\n",
    "        var_control_priors  = zeros(T)\n",
    "        mean_goal_priors    = zeros(T)\n",
    "        var_goal_priors     = zeros(T)\n",
    "        mean_current_state_prior = zeros(2)\n",
    "        cov_current_state_prior  = zeros(2, 2)\n",
    "        execution_time           = Subject(Float64)\n",
    "        vmp_iterations           = BehaviorSubject(5)\n",
    "        recent_action            = RecentSubject(Float64)\n",
    "        free_energy              = Subject(Float64)\n",
    "        the_goal_in_radians      = BehaviorSubject(3.14)\n",
    "        the_goal_variance        = BehaviorSubject(1e-3)\n",
    "        subscriptions            = []\n",
    "        \n",
    "        agent = new(datastream, nothing, \n",
    "            mean_control_priors, var_control_priors,\n",
    "            mean_goal_priors, var_goal_priors,\n",
    "            mean_current_state_prior, cov_current_state_prior,\n",
    "            subscriptions, execution_time, vmp_iterations, recent_action, \n",
    "            free_energy, the_goal_in_radians, the_goal_variance,\n",
    "        )\n",
    "        \n",
    "        reset!(agent)\n",
    "        \n",
    "        return agent\n",
    "    end\n",
    "end\n",
    "\n",
    "# This function simply resets the state of the `agent`\n",
    "# Can be used in real-time during simulations\n",
    "function reset!(agent::SuperSmartRxInferAgent) \n",
    "    fill!(agent.mean_control_priors, 0.0)\n",
    "    fill!(agent.var_control_priors, huge)\n",
    "    fill!(agent.mean_goal_priors, 0.0)\n",
    "    fill!(agent.var_goal_priors, huge)\n",
    "    agent.mean_current_state_prior = [ 0.0, 0.0 ]\n",
    "    agent.cov_current_state_prior = tiny * diageye(2)\n",
    "    \n",
    "    return nothing\n",
    "end\n",
    "\n",
    "# This function is the HEART of our super smart AI agent\n",
    "# The inference starts only when the `start!` is called\n",
    "function start!(agent::SuperSmartRxInferAgent)   \n",
    "    \n",
    "    if !isnothing(agent.rxinfer_engine)\n",
    "        stop!(agent)\n",
    "    end\n",
    "    \n",
    "    # These functions implement the slide logic from \n",
    "    # Thijs van der Laar \"Automated Design of Bayesian Signal Processing Algorithms\"\n",
    "    shift_mean_control_priors = shift(agent.mean_control_priors, 0.0)\n",
    "    shift_var_control_priors  = shift(agent.var_control_priors, huge)\n",
    "    shift_mean_goal_priors    = shift(agent.mean_goal_priors, agent.the_goal_in_radians)\n",
    "    shift_var_goal_priors     = shift(agent.var_goal_priors, agent.the_goal_variance)\n",
    "\n",
    "    # Inferred variance is very small, causes numerical instabilities\n",
    "    # I replaced it with `1e-2`, which seems to work fine\n",
    "    pick_first_action = (actions) -> begin\n",
    "        return mean_var(first(actions))\n",
    "    end\n",
    "    \n",
    "    # We soften noise posterior to update its prior on the next time step\n",
    "    soft_noise_prior = (noise) -> begin \n",
    "        μ = mean(noise)\n",
    "        μ = μ > 0.1 ? 0.1 : μ # It doesn't make sense to have noise more than `0.1`\n",
    "        v = 0.1\n",
    "        α = μ ^ 2 / v + 2\n",
    "        θ = μ * (α - 1)\n",
    "        return (α, θ)\n",
    "    end\n",
    "    \n",
    "    # A simple logic to update the agent's prior automatically\n",
    "    autoupdates = @autoupdates begin \n",
    "        m_u = shift_mean_control_priors(q(u))\n",
    "        v_u = shift_var_control_priors(q(u))\n",
    "        m_x = shift_mean_goal_priors(q(x))\n",
    "        v_x = shift_var_goal_priors(q(x))\n",
    "        m_u_t_min, v_u_t_min = pick_first_action(q(u))\n",
    "        n_alpha, n_theta = soft_noise_prior(q(n))\n",
    "    end\n",
    "       \n",
    "    # In the beginning initial forces are simply vague Gaussian distributions with huge variance\n",
    "    initial_forces = map(agent.mean_control_priors, agent.var_control_priors) do m, v\n",
    "        return NormalMeanVariance(m, v)\n",
    "    end\n",
    "    \n",
    "    # Prediction time horizon\n",
    "    T = length(agent.mean_control_priors)\n",
    "    \n",
    "    # This is very experimental, may break at any moment :)\n",
    "    # But works relatively stable, that should go to the stable API\n",
    "    iterations_ref = Ref(0)\n",
    "    \n",
    "    vmp_iterations_subscription = subscribe!(agent.vmp_iterations, (vmp_iters) -> begin \n",
    "        iterations_ref[] = vmp_iters\n",
    "        # This is highly experimental, we should create a better API for this\n",
    "        # This code reinstantiates the internal free energy counting procedure\n",
    "        # such that it does not break when we change the number of VMP iterations\n",
    "        if !(isnothing(agent.rxinfer_engine))\n",
    "            agent.rxinfer_engine.fe_actor.score = zeros(vmp_iters, 30)\n",
    "            agent.rxinfer_engine.fe_actor.cframe = 1\n",
    "            agent.rxinfer_engine.fe_actor.cindex = 0\n",
    "            agent.rxinfer_engine.fe_actor.valid = falses(30)\n",
    "        end\n",
    "    end)\n",
    "        \n",
    "    # Here is the most important part of the function, \n",
    "    # which creates the brain of the agent, check the `?rxinference` for comprehensive documentation\n",
    "    engine = rxinference(\n",
    "        model = pendulum(T),\n",
    "        meta = pendulum_meta(),\n",
    "        constraints = pendulum_constraints(),\n",
    "        datastream = agent.datastream,\n",
    "        autoupdates = autoupdates,\n",
    "        initmarginals = (u = initial_forces, n = InverseGamma(4.0, 1.0)),\n",
    "        autostart = false,\n",
    "        returnvars = (:u, ),\n",
    "        historyvars = (u = KeepLast(), s_t = KeepLast(), n = KeepLast()),\n",
    "        keephistory = 30,\n",
    "        free_energy = true,\n",
    "        free_energy_diagnostics = nothing,\n",
    "        iterations = iterations_ref,\n",
    "        events = Val((:before_auto_update, :on_tick))\n",
    "    )\n",
    "        \n",
    "    # This is quite useful, should we make this a standard feature? Probably, yes!!\n",
    "    before_update_events = engine.events |> filter(event -> event isa RxInferenceEvent{:before_auto_update}) \n",
    "    on_tick_events = engine.events |> filter(event -> event isa RxInferenceEvent{:on_tick}) \n",
    "         \n",
    "    # We manually update the prior for the current state, the `@autoupdates` macro is a bit \n",
    "    # restrictive here as it does not allow to use external variables, such as `agent`\n",
    "    prior_subscription = subscribe!(before_update_events, (args...) -> begin\n",
    "        update!(engine.model[:m_s_t_min], agent.mean_current_state_prior)\n",
    "        update!(engine.model[:v_s_t_min], agent.cov_current_state_prior)\n",
    "    end)\n",
    "    \n",
    "    # Slide logic for current state, a bit tricky, check Thijs' PhD thesis\n",
    "    # This is the only iffy part of the notebook, we may need to create a proper API for this\n",
    "    on_tick_subscription = subscribe!(on_tick_events, (args...) -> begin \n",
    "        slide_msg_idx = 3    # This is model dependent (needs better API)\n",
    "        predictive_message = getrecent(messageout(engine.model[:s][1], slide_msg_idx)) # Get a predictive message\n",
    "            \n",
    "        (m_s_t_min, v_s_t_min) = mean_cov(predictive_message) \n",
    "    \n",
    "        agent.mean_current_state_prior = m_s_t_min\n",
    "        agent.cov_current_state_prior = v_s_t_min\n",
    "    end)\n",
    "        \n",
    "    # Agent exposes the actions stream even if its disabled\n",
    "    # It starts sending messages only after the `start` function has been executed\n",
    "    recent_action_subscription = subscribe!(engine.posteriors[:u], (actions) -> begin \n",
    "        next!(agent.recent_action, mode(first(actions)))\n",
    "    end)\n",
    "\n",
    "    # Same for free energy, exposed free energy stream sends values only after `start`\n",
    "    free_energy_subscription = subscribe!(engine.free_energy, (value) -> begin \n",
    "        next!(agent.free_energy, value)\n",
    "    end)\n",
    "\n",
    "    # Put subscriptions in an array so we can unsubscribe later on request\n",
    "    push!(agent.subscriptions, vmp_iterations_subscription)\n",
    "    push!(agent.subscriptions, prior_subscription)\n",
    "    push!(agent.subscriptions, on_tick_subscription)\n",
    "    push!(agent.subscriptions, recent_action_subscription)\n",
    "    push!(agent.subscriptions, free_energy_subscription)\n",
    "    \n",
    "    agent.rxinfer_engine = engine\n",
    "    \n",
    "    # EVERYTHING IS READY!\n",
    "    # We can start the engine!\n",
    "    RxInfer.start(engine)\n",
    "\n",
    "    return nothing\n",
    "end\n",
    "\n",
    "function stop!(agent::SuperSmartRxInferAgent)\n",
    "    if !isnothing(agent.rxinfer_engine)\n",
    "        RxInfer.stop(agent.rxinfer_engine)\n",
    "    end\n",
    "    foreach(subscription -> unsubscribe!(subscription), agent.subscriptions)\n",
    "    agent.rxinfer_engine = nothing\n",
    "    agent.subscriptions = []\n",
    "    return nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcc8ce7",
   "metadata": {},
   "source": [
    "# The most exciting part of the notebook\n",
    "\n",
    "**NOTE**: Note again that Julia initial compilation times are sometimes slow, so the initial execution of this cell takes some time to precompile. Also the `Activate agent` takes some time to precompile the agent, but after the initial compilation the code executes very fast.\n",
    "\n",
    "Making all run together! Fun fact: 99% code below is just plotting stuff. Slider ranges are controlled in the `SliderGrid` structure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70c7426e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ObserverFunction defined at In[9]:203 operating on Observable{Any}(0.001)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup the space ship's dashboard\n",
    "\n",
    "# Some naming guidelines\n",
    "# `r_*` - indicates *R*eactive observable, either from `Observables.jl` or from `Rocket.jl`\n",
    "# `s_*` - indicates a *S*ubscription\n",
    "# `b_*` - indicates a *B*utton\n",
    "\n",
    "# Width of the controls\n",
    "c_width = 950\n",
    "c_fontsize = 35\n",
    "\n",
    "fig = Figure(fontsize = c_fontsize, resolution = (1920, 1080))\n",
    "\n",
    "controls_grid = fig[1:4, 1] = GridLayout()\n",
    "pendulum_grid = fig[1:4, 2:4] = GridLayout()\n",
    "auxilary_grid = fig[1:4, 5] = GridLayout()\n",
    "\n",
    "display(fig, title = \"RxInfer in action\")\n",
    "\n",
    "free_energy_buffer = CircularBuffer{Float64}(100)\n",
    "\n",
    "r_world_isrunning = Observable(true) # Is simulation running\n",
    "r_origin = Observable([ Point2f(0, 0), Point2f(0, 0) ]) # Position of the origin\n",
    "r_rod  = Observable([ Point2f(0, 0), Point2f(0, 0) ]) # Position of the rod\n",
    "r_bob  = Observable([ Point2f(0, 0) ])  # Position of the bob\n",
    "r_goal = Observable([ Point2f(0, 0) ]) # Position of the goal\n",
    "r_observations = Observable(Point2f[]) # Positions of noibsy observations (history)\n",
    "r_actions      = Observable([ Point2f(0, 0), Point2f(0, 0) ]) # Actions (history)\n",
    "r_noise_history = Observable(map(_ -> Point2f(0, 0), 1:30)) # Inferred noise (history)\n",
    "r_noise_bandl   = Observable(map(_ -> Point2f(0, 0), 1:30)) # Inferred noise lower band (history)\n",
    "r_noise_bandu   = Observable(map(_ -> Point2f(0, 0), 1:30)) # Inferred noise upper band (history)\n",
    "r_free_energy     = Observable([ Point2f(0, 0) ])\n",
    "r_free_energy_acc = Observable([ Point2f(0, 0) ])\n",
    "    \n",
    "ax_actions_history = Axis(auxilary_grid[1, 1], limits = (0, 30, -1.5, 1.5), title = \"Agents actions\")\n",
    "    \n",
    "lines!(ax_actions_history, r_actions; linewidth = 4, color = :blue)\n",
    "   \n",
    "# Dashboard buttons and sliders\n",
    "b_grid = controls_grid[2, 1] = GridLayout()\n",
    "\n",
    "b_run    = Button(b_grid[1, 1]; label = \"Activate agent\", width = c_width / 2, fontsize = c_fontsize)\n",
    "b_areset = Button(b_grid[2, 1]; label = \"Erase agents's memory\", width = c_width / 2, fontsize = c_fontsize)\n",
    "b_stop   = Button(b_grid[3, 1]; label = \"Deactivate agent\", width = c_width / 2, fontsize = c_fontsize)\n",
    "\n",
    "b_corrupt = Button(b_grid[1, 2]; label = \"Corrupt world's state\", width = c_width / 2, fontsize = c_fontsize)\n",
    "b_wreset = Button(b_grid[2, 2]; label = \"Reset world's parameters\", width = c_width / 2, fontsize = c_fontsize)\n",
    "\n",
    "\n",
    "\n",
    "sg = SliderGrid(\n",
    "    controls_grid[1, 1],\n",
    "    (label = \"Bob's mass\", range = 0.15:0.01:0.35, format = \"{:.3f}g\", startvalue = parameters.bob_mass, ),\n",
    "    (label = \"Rod's Length\", range = 0.15:0.01:0.25, format = \"{:.3f}cm\", startvalue = parameters.rod_length),\n",
    "    (label = \"Maximum engine power\", range = 0.1:0.1:1.5, format = \"{:.1f}\", startvalue = parameters.engine_max_power),\n",
    "    (label = \"Pendulum's friction\", range = 0.1:0.01:0.3, format = \"{:.3f}\", startvalue = parameters.friction),\n",
    "    (label = \"World's gravity\", range = 1.0:0.1:50.0, format = \"{:.1f}\", startvalue = parameters.gravity),\n",
    "    (label = \"Observational noise\", range = exp10.(-8.0:0.1:-2), format = \"{:.6f}\", startvalue = parameters.observations_noise),\n",
    "    (label = \"VMP iterations\", range = 1:25, startvalue = 5),\n",
    "    (label = \"Goal\", range = 0:0.01:2pi, startvalue = pi),\n",
    "    (label = \"Goal variance\", range = exp10.(-5.0:0.1:-2), startvalue = exp10(-3)),\n",
    "    width = c_width,\n",
    "    tellwidth = true,\n",
    "    tellheight = true\n",
    ")\n",
    "\n",
    "r_mass = sg.sliders[1].value\n",
    "r_length = sg.sliders[2].value\n",
    "r_power = sg.sliders[3].value\n",
    "r_friction = sg.sliders[4].value\n",
    "r_gravity = sg.sliders[5].value\n",
    "r_noise = sg.sliders[6].value\n",
    "r_iters = sg.sliders[7].value\n",
    "r_goalp = sg.sliders[8].value\n",
    "r_goalv = sg.sliders[9].value\n",
    "\n",
    "ax_limits   = (-0.3, 0.3, -0.3, 0.3)\n",
    "ax_pendulum = Axis(pendulum_grid[1, 1], limits = ax_limits, title = \"Pendulum\", aspect = DataAspect())\n",
    "\n",
    "lines!(ax_pendulum, r_rod; linewidth = 5, color = :black)\n",
    "scatter!(ax_pendulum, r_origin; strokewidth = 2, strokecolor = :black, color = :black, markersize = 20)\n",
    "scatter!(ax_pendulum, r_bob; strokewidth = 2, strokecolor = :black, color = :black, markersize = map(m -> m * 500, r_mass))\n",
    "scatter!(ax_pendulum, r_goal; strokewidth = 4, strokecolor = :red, color = (:red, 0.2), markersize = 120)\n",
    "scatter!(ax_pendulum, r_observations; strokecolor = :green, color = (:green, :0.2), markersize = map(m -> m * 75, r_mass))\n",
    "\n",
    "ax_inferred_noise_history = Axis(auxilary_grid[2, 1], yscale = log10, limits = (0, 30, 1e-8, 1.0), title = \"Inference history of the noise component\")\n",
    "\n",
    "lines!(ax_inferred_noise_history, r_noise_history; linewidth = 4, color = :blue)\n",
    "band!(ax_inferred_noise_history, r_noise_bandl, r_noise_bandu, color = (:blue, 0.2))\n",
    "hlines!(ax_inferred_noise_history, map(e -> [ e ], r_noise), color = :red)\n",
    "\n",
    "ax_free_energy_history = Axis(auxilary_grid[3, 1], limits = ((0, 100), nothing), xticklabelsvisible = false, yticklabelsvisible = false, title = \"Bethe Free Energy\")\n",
    "lines!(ax_free_energy_history, r_free_energy)\n",
    "\n",
    "ax_free_energy_acc_history = Axis(auxilary_grid[4, 1], limits = ((1, 15), nothing), xticklabelsvisible = true, yticklabelsvisible = false, title = \"BFE minimization history\")\n",
    "lines!(ax_free_energy_acc_history, r_free_energy_acc)\n",
    "\n",
    "## Initialize the environment    \n",
    "\n",
    "world = PendulumWorld()\n",
    "agent = SuperSmartRxInferAgent(3, labeled(Val((:x_t, )), combineLatest(world.noisy_observations)))    \n",
    "\n",
    "# Redraw the observations as soon as we have a new data point\n",
    "s_ticks = subscribe!(world.ticks, (_) -> begin \n",
    "    r_observations[] = map(angle -> pendulum_bob_position(angle), world.observations_history)\n",
    "    r_actions[] = map(((index, force), ) -> Point2f(index, force), enumerate(world.actions_history))\n",
    "    r_free_energy[] = map(((index, value), ) -> Point2f(index, value), enumerate(free_energy_buffer))\n",
    "\n",
    "    if !isnothing(agent.rxinfer_engine)\n",
    "        if length(agent.rxinfer_engine.history[:n]) == 30\n",
    "            rfem, rfev = mean(free_energy_buffer), clamp(var(free_energy_buffer), 1e-4, Inf)\n",
    "            if !isnan(rfem) && !isinf(rfem) && !isnan(rfev) && !isinf(rfev)\n",
    "                ylims!(ax_free_energy_history, clamp(rfem - 20sqrt(rfev), 1e-8, Inf), rfem + 20sqrt(rfev))\n",
    "            end\n",
    "            rfeaccmin, rfeaccmax = minimum(agent.rxinfer_engine.free_energy_history), maximum(agent.rxinfer_engine.free_energy_history)\n",
    "            rfeaccm, rfeaccv = mean(agent.rxinfer_engine.free_energy_history), clamp(var(agent.rxinfer_engine.free_energy_history), 1e-4, Inf)\n",
    "            if !isnan(rfeaccm) && !isinf(rfeaccm) && !isnan(rfeaccv) && !isinf(rfeaccv)\n",
    "                xlims!(ax_free_energy_acc_history, 1, length(agent.rxinfer_engine.free_energy_history))\n",
    "                ylims!(ax_free_energy_acc_history, clamp(rfeaccmin - sqrt(rfeaccv), 1e-8, Inf), rfeaccmax + sqrt(rfeaccv))\n",
    "            end\n",
    "        \n",
    "            noise_means = map((q_n) -> mean(q_n), agent.rxinfer_engine.history[:n])\n",
    "            noise_vars = map((q_n) -> var(q_n), agent.rxinfer_engine.history[:n])\n",
    "            r_free_energy_acc[] = map(((index, value), ) -> Point2f(index, value), enumerate(agent.rxinfer_engine.free_energy_history))\n",
    "            r_noise_history[] = map(((index, mean), ) -> Point2f(index, mean), enumerate(noise_means))\n",
    "            r_noise_bandl[] = map(((index, mean), var) -> Point2f(index, clamp(mean - sqrt(var), 1e-10, Inf)), enumerate(noise_means), noise_vars)\n",
    "            r_noise_bandu[] = map(((index, mean), var) -> Point2f(index, clamp(mean + sqrt(var), 1e-10, Inf)), enumerate(noise_means), noise_vars)\n",
    "        end\n",
    "    end\n",
    "end)\n",
    "\n",
    "s_redraw = subscribe!(combineLatest(world.noise_free_observations, agent.the_goal_in_radians), ((angle, goal), ) -> begin\n",
    "    origin_position = Point2f(0.0, 0.0)\n",
    "    bob_position    = pendulum_bob_position(angle)\n",
    "    r_rod[] = [ origin_position, bob_position ]\n",
    "    r_bob[] = [ bob_position ]\n",
    "    r_goal[] = [ pendulum_bob_position(goal) ]\n",
    "end)\n",
    "\n",
    "# Register a new action as soon as we have it\n",
    "s_actions = subscribe!(agent.recent_action, (a) -> register_next_action(world, a))\n",
    "s_free_energy = subscribe!(agent.free_energy, (v) -> push!(free_energy_buffer, v))\n",
    "    \n",
    "## START THE SHOW!!\n",
    "\n",
    "# The world runs independently of the agent, but can be force-stopped as well\n",
    "@async begin\n",
    "    try \n",
    "        while isopen(fig.scene) && r_world_isrunning[]\n",
    "            tick(world) \n",
    "            sleep(1 / 60)\n",
    "        end\n",
    "    catch err\n",
    "        println(\"An error happened inside our beautiful world!\")\n",
    "        showerror(stderr, err, catch_backtrace())\n",
    "    end\n",
    "    unsubscribe!(s_actions)\n",
    "    unsubscribe!(s_free_energy)\n",
    "    unsubscribe!(s_ticks)\n",
    "    unsubscribe!(s_redraw)\n",
    "end\n",
    "    \n",
    "\n",
    "\n",
    "# Implement buttons logic\n",
    "    \n",
    "on(b_run.clicks) do clicks\n",
    "    reset!(agent)\n",
    "    start!(agent)\n",
    "end\n",
    "        \n",
    "on(b_areset.clicks) do clicks\n",
    "    reset!(agent)\n",
    "end\n",
    "        \n",
    "on(b_corrupt.clicks) do clicks\n",
    "    world.pendulum_hidden_state = (0.0, 0.0)\n",
    "end\n",
    "  \n",
    "on(b_wreset.clicks) do clicks \n",
    "    local rparams = PendulumWorldParameters()\n",
    "    r_length[] = parameters.rod_length = rparams.rod_length\n",
    "    r_mass[] = parameters.bob_mass = rparams.bob_mass\n",
    "    r_friction[] = parameters.friction = rparams.friction\n",
    "    r_gravity[] = parameters.gravity = rparams.gravity\n",
    "    r_power[] = parameters.engine_max_power = rparams.engine_max_power\n",
    "    r_noise[] = parameters.observations_noise = rparams.observations_noise\n",
    "    parameters.worlds_clock_Δt = rparams.worlds_clock_Δt\n",
    "end\n",
    "        \n",
    "on((_) -> stop!(agent), b_stop.clicks)\n",
    "    \n",
    "# Implement sliders logic\n",
    "    \n",
    "on((length) -> begin global parameters.rod_length = length end, r_length)\n",
    "on((mass) -> begin global parameters.bob_mass = mass end, r_mass)\n",
    "on((power) -> begin global parameters.engine_max_power = power end, r_power)\n",
    "on((friction) -> begin global parameters.friction = friction end, r_friction)\n",
    "on((gravity) -> begin global parameters.gravity = gravity end, r_gravity)\n",
    "on((noise) -> begin global parameters.observations_noise = noise end, r_noise)\n",
    "on((iters) -> begin next!(agent.vmp_iterations, iters) end, r_iters)\n",
    "on((goal) -> begin next!(agent.the_goal_in_radians, goal) end, r_goalp)\n",
    "on((var) -> begin next!(agent.the_goal_variance, var) end, r_goalv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8973a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
