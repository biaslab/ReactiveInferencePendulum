{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4836ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "using GLMakie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "17cc1929",
   "metadata": {},
   "outputs": [],
   "source": [
    "using RxInfer, Rocket\n",
    "\n",
    "import ReactiveMP: getrecent, messageout\n",
    "import Rocket: subscribe!\n",
    "import Base: show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "582c9a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamical parameters\n",
    "m = 0.65 # grams\n",
    "l = 0.85 # cm\n",
    "b = 0.7 # friction\n",
    "g = 9.81 # gravity\n",
    "N = 200\n",
    "# Time horizon\n",
    "T = 30\n",
    "O = [1.0; 0.0]\n",
    "c = 0.1\n",
    "\n",
    "#C = 4, T = 30\n",
    "#C = 5, T = 5\n",
    "\n",
    "# Time step size\n",
    "Δt = 0.07;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7e47e343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "f_arctanh (generic function with 1 method)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Internal dynamic model\n",
    "# We asume the dynamical model is known for now\n",
    "# Its interesting to extend this further and try to actually infer all parameters\n",
    "function dzdt(z_t_min, u) \n",
    "    # Transition function modeling transition due to gravity, friction and engine control\n",
    "    (θ, θ̇) = z_t_min\n",
    "    θ̈ = 1/(m*l^2)*(-m*g*l*sin(θ) - b*θ̇ .+ u)\n",
    "    Δz = [ θ̇, θ̈ ]\n",
    "    z_t = z_t_min .+  Δz .* Δt\n",
    "    return z_t\n",
    "end\n",
    "\n",
    "f_tanh(u)    = c * tanh(u)\n",
    "f_arctanh(ū) = atanh(clamp(ū, -c+1e-3, c-1e-3) / c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "0e2fda4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "observe (generic function with 1 method)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# BEHOLD THE WORLD\n",
    "mutable struct PendulumWorld\n",
    "    real_pendulum_position :: Float64\n",
    "    real_pendulum_velocity :: Float64\n",
    "    \n",
    "    PendulumWorld() = new(0.0, 0.0)\n",
    "end\n",
    "\n",
    "Base.show(io::IO, world::PendulumWorld) = print(io, \"PendulumWorld()\")\n",
    "\n",
    "function act(world::PendulumWorld, action::Float64)\n",
    "    hidden_state = (world.real_pendulum_position, world.real_pendulum_velocity)\n",
    "    next_hidden_state = dzdt(hidden_state, f_tanh(action))\n",
    "        \n",
    "    world.real_pendulum_position = next_hidden_state[1]\n",
    "    world.real_pendulum_velocity = next_hidden_state[2]\n",
    "    \n",
    "    return observe(world)\n",
    "end\n",
    "\n",
    "function observe(world::PendulumWorld)\n",
    "    return mod(rand(Normal(world.real_pendulum_position, 0.001)), 2pi)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3af4a730",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pendulum_meta (generic function with 1 method)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@model function pendulum(T)\n",
    "    # Internal model perameters\n",
    "    Gamma = 1e10*diageye(2) # Transition precision\n",
    "    Theta = 1e-4 # Observation variance\n",
    "    cO = constvar(O) # Observation matrix\n",
    "    \n",
    "    m_s_t_min = datavar(Vector{Float64})\n",
    "    V_s_t_min = datavar(Matrix{Float64})\n",
    "\n",
    "    s_t_min ~ MvNormal(mean = m_s_t_min, cov = V_s_t_min)\n",
    "    s_k_min = s_t_min\n",
    "    \n",
    "    m_u = datavar(Float64, T)\n",
    "    V_u = datavar(Float64, T)\n",
    "    \n",
    "    m_x = datavar(Float64, T)\n",
    "    V_x = datavar(Float64, T)\n",
    "    \n",
    "    u = randomvar(T)\n",
    "    s = randomvar(T)\n",
    "    x = randomvar(T)\n",
    "    \n",
    "    u_s = randomvar(T)\n",
    "    u_constrained = randomvar(T)\n",
    "    \n",
    "    for k in 1:T\n",
    "        u[k] ~ Normal(mean = m_u[k], var = V_u[k])\n",
    "        u_constrained[k] ~ f_tanh(u[k])\n",
    "        u_s[k] ~ dzdt(s_k_min, u_constrained[k])\n",
    "        s[k] ~ MvNormal(mean = u_s[k], precision = Gamma)\n",
    "        x[k] ~ Normal(mean = dot(cO, s[k]), variance = Theta)\n",
    "        x[k] ~ Normal(mean = m_x[k], variance = V_x[k]) # goal\n",
    "        s_k_min = s[k]\n",
    "    end\n",
    "    \n",
    "    return (s, )\n",
    "end\n",
    "\n",
    "@meta function pendulum_meta()\n",
    "    dzdt() -> DeltaMeta(method = Linearization())\n",
    "    f_tanh() -> DeltaMeta(method = Unscented(kappa=1e-2), inverse=f_arctanh)\n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "6c6652ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "mutable struct SuperSmartRxInferAgent\n",
    "    rxinfer_engine           :: Union{Nothing, RxInferenceEngine}\n",
    "    the_goal_in_radians      :: Float64 \n",
    "    the_goal_variance        :: Float64\n",
    "    mean_control_priors      :: Vector{Float64}\n",
    "    var_control_priors       :: Vector{Float64}\n",
    "    mean_goal_priors         :: Vector{Float64}\n",
    "    var_goal_priors          :: Vector{Float64}\n",
    "    mean_current_state_prior :: Vector{Float64}\n",
    "    cov_current_state_prior  :: Matrix{Float64}\n",
    "    \n",
    "    function SuperSmartRxInferAgent(T)\n",
    "        mean_control_priors = Float64[ 0.0 for _ in 1:T ]\n",
    "        var_control_priors  = Float64[ huge for _ in 1:T ]\n",
    "\n",
    "        mean_goal_priors = Float64[ 0.0 for _ in 1:T ]\n",
    "        var_goal_priors = Float64[ huge for _ in 1:T ]\n",
    "\n",
    "        the_goal_in_radians = 3.14\n",
    "        the_goal_variance   = 1e-4\n",
    "\n",
    "        mean_current_state_prior = [ 0.0, 0.0 ]\n",
    "        cov_current_state_prior  = tiny * diageye(2)\n",
    "\n",
    "        return new(\n",
    "            nothing, \n",
    "            the_goal_in_radians, \n",
    "            the_goal_variance,\n",
    "            mean_control_priors,\n",
    "            var_control_priors,\n",
    "            mean_goal_priors,\n",
    "            var_goal_priors,\n",
    "            mean_current_state_prior,\n",
    "            cov_current_state_prior\n",
    "        )\n",
    "    end\n",
    "end\n",
    "\n",
    "Base.show(io::IO, agent::SuperSmartRxInferAgent) = print(io, \"SuperSmartRxInferAgent()\")\n",
    "\n",
    "# Shift a vector and put a new value at the end\n",
    "function shift(vector, value)\n",
    "    return (_) -> begin \n",
    "        @inbounds for i in firstindex(vector):lastindex(vector)-1\n",
    "            vector[i] = vector[i + 1]\n",
    "        end\n",
    "        vector[end] = value\n",
    "        return vector\n",
    "    end\n",
    "end\n",
    "\n",
    "function Rocket.subscribe!(agent::SuperSmartRxInferAgent, datastream)\n",
    "    T = length(agent.mean_control_priors)\n",
    "    \n",
    "    recent_action = RecentSubject(Float64)\n",
    "        \n",
    "    next!(recent_action, 0.0)\n",
    "    \n",
    "    shift_mean_control_priors = (_) -> begin \n",
    "        shift(agent.mean_control_priors, 0.0)\n",
    "        agent.mean_control_priors[begin] = Rocket.getrecent(recent_action)\n",
    "        return agent.mean_control_priors\n",
    "    end\n",
    "    \n",
    "    shift_var_control_priors  = (_) -> begin \n",
    "        shift(agent.var_control_priors, huge)\n",
    "        agent.var_control_priors[begin] = tiny\n",
    "        return agent.var_control_priors\n",
    "    end\n",
    "    \n",
    "    # A simple logic to update the agent's prior automatically\n",
    "    autoupdates = @autoupdates begin \n",
    "        m_u = shift_mean_control_priors(q(u))\n",
    "        V_u = shift_var_control_priors(q(u))\n",
    "    end\n",
    "        \n",
    "    engine = rxinference(\n",
    "        model = pendulum(T),\n",
    "        meta = pendulum_meta(),\n",
    "        datastream = datastream,\n",
    "        autoupdates = autoupdates,\n",
    "        initmarginals = (\n",
    "            u = map((m, v) -> NormalMeanVariance(m, v), agent.mean_current_state_prior, agent.var_control_priors),\n",
    "        ),\n",
    "        autostart = false,\n",
    "        returnvars = (:u, ),\n",
    "    )\n",
    "        \n",
    "    update!(engine.model[:m_s_t_min], agent.mean_current_state_prior)\n",
    "    update!(engine.model[:V_s_t_min], agent.cov_current_state_prior)\n",
    "    \n",
    "    # Slide logic\n",
    "    slide_callback = (_) -> begin\n",
    "        slide_msg_idx = 3 # This is model dependent\n",
    "        (s, ) = engine.returnval\n",
    "        \n",
    "        (m_s_t_min, V_s_t_min) = mean_cov(getrecent(messageout(s[2], slide_msg_idx))) # Reset prior state statistics;\n",
    "    \n",
    "        agent.mean_current_state_prior = m_s_t_min\n",
    "        agent.cov_current_state_prior = V_s_t_min\n",
    "            \n",
    "        update!(engine.model[:m_s_t_min], agent.mean_current_state_prior)\n",
    "        update!(engine.model[:V_s_t_min], agent.cov_current_state_prior)\n",
    "    end\n",
    "    \n",
    "    slide_subscription = subscribe!(engine.posteriors[:u], slide_callback)\n",
    "        \n",
    "    recent_action_subscription = subscribe!(engine.posteriors[:u], (actions) -> begin \n",
    "        next!(recent_action, mode(actions[2]))\n",
    "    end)\n",
    "    \n",
    "    \n",
    "    agent.rxinfer_engine = engine\n",
    "    \n",
    "    RxInfer.start(engine)\n",
    "    \n",
    "    return recent_action, () -> begin \n",
    "        unsubscribe!(slide_subscription)\n",
    "        unsubscribe!(recent_action_subscription)\n",
    "        RxInfer.stop(agent.rxinfer_engine)\n",
    "        agent.rxinfer_engine = nothing\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "3b454b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "initializeAgent (generic function with 1 method)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Because states of the agent are unknown to the world, we wrap them in a comprehension.\n",
    "# The comprehension only returns functions for interacting with the agent.\n",
    "# Internal beliefs cannot be directly observed, and interaction is only allowed through the Markov blanket\n",
    "function initializeAgent(T)\n",
    "    Epsilon = huge # Control prior variance\n",
    "    m_u = Float64[ 0.0 for k=1:T ] # Set control priors\n",
    "    V_u = Float64[ Epsilon for k=1:T ]\n",
    "\n",
    "    x_target = 3.14 # Goal state\n",
    "    Sigma = 1e-4 # Goal prior variance\n",
    "    m_x = [0.0 for k=1:T]\n",
    "    m_x[end] = x_target\n",
    "    V_x = convert(Vector{Float64}, [huge for k=1:T])\n",
    "    V_x[end] = Sigma # Set prior to reach goal at t=T\n",
    "\n",
    "    m_s_t_min = [0.0, 0.0] # Set initial brain state prior\n",
    "    V_s_t_min = tiny*diageye(2)\n",
    "    \n",
    "    result = nothing\n",
    "\n",
    "    # Initialize messages and marginals dictionary\n",
    "\n",
    "    function infer(upsilon_t::Float64, y_hat_t::Float64)\n",
    "        m_u[1] = upsilon_t # Register action with the generative model\n",
    "        V_u[1] = tiny # Clamp control prior to performed action\n",
    "\n",
    "        m_x[1] = y_hat_t # Register observation with the generative model\n",
    "        V_x[1] = tiny # Clamp goal prior to observation\n",
    "\n",
    "        data = Dict(:m_u       => m_u, \n",
    "                    :V_u       => V_u, \n",
    "                    :m_x       => m_x, \n",
    "                    :V_x       => V_x,\n",
    "                    :m_s_t_min => m_s_t_min,\n",
    "                    :V_s_t_min => V_s_t_min)\n",
    "\n",
    "        result = inference(\n",
    "            model = pendulum(T),\n",
    "            meta = pendulum_meta(),\n",
    "            data = data,\n",
    "        )\n",
    "    end\n",
    "    \n",
    "    function act() \n",
    "        if result !== nothing\n",
    "            return mode(result.posteriors[:u][2])[1]\n",
    "        else\n",
    "            return 0.0\n",
    "        end\n",
    "    end\n",
    "\n",
    "    function slide(slide_msg_idx = 3)\n",
    "        (s, ) = result.returnval\n",
    "        (m_s_t_min, V_s_t_min) = mean_cov(getrecent(messageout(s[2], slide_msg_idx))) # Reset prior state statistics;\n",
    "\n",
    "        m_u = circshift(m_u, -1)\n",
    "        m_u[end] = 0.0\n",
    "        V_u = circshift(V_u, -1)\n",
    "        V_u[end] = Epsilon\n",
    "\n",
    "        m_x = circshift(m_x, -1)\n",
    "        m_x[end] = x_target\n",
    "        V_x = circshift(V_x, -1)\n",
    "        V_x[end] = Sigma\n",
    "    end\n",
    "\n",
    "    return (infer, act, slide)    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fd324a4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "animstep! (generic function with 1 method)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function animstep!(rod,Θ)\n",
    "    \n",
    "    rod[] = [Point2f(0, 0), Point2f(l*sin(Θ), -l*cos(Θ))]\n",
    "    balls[] = [Point2f(l*sin(Θ), -l*cos(Θ))]\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e13e6928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.0005612499457319316 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ObserverFunction defined at In[105]:65 operating on Observable{Any}(0)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1 = 0.5\n",
    "y1 = 0.5\n",
    "rod   = Observable([Point2f(0, 0), Point2f(x1, y1)])\n",
    "balls = Observable([Point2f(x1, y1)])\n",
    "fig = Figure(); display(fig)\n",
    "ax = Axis(fig[1,1])\n",
    "\n",
    "lines!(ax, rod; linewidth = 4, color = :blue)\n",
    "scatter!(ax, balls; marker = 'o', strokewidth = 2,\n",
    "    strokecolor = :black,\n",
    "    color = :black, markersize = [30]\n",
    ")\n",
    "xlims!(ax, -1.5l, 1.5l)\n",
    "ylims!(ax, -1.5l, 1.5l)\n",
    "ax.title = \"Pendulum\"\n",
    "ax.aspect = DataAspect()\n",
    "\n",
    "world = PendulumWorld()\n",
    "\n",
    "agent = SuperSmartRxInferAgent(T)\n",
    "\n",
    "ys = Subject(Float64)\n",
    "\n",
    "# subscribe!(ys, logger())\n",
    "\n",
    "observations = combineLatest(ys, of(tiny)) |> map(Tuple{Vector{Float64}, Vector{Float64}}, ((cx, cV),) -> begin\n",
    "    shift(agent.mean_goal_priors, agent.the_goal_in_radians)(nothing)\n",
    "    shift(agent.var_goal_priors, agent.the_goal_variance)(nothing)\n",
    "    agent.mean_goal_priors[begin] = cx\n",
    "    agent.var_goal_priors[begin] = cV\n",
    "    return (agent.mean_goal_priors, agent.var_goal_priors)\n",
    "end)\n",
    "\n",
    "datastream = labeled(Val((:m_x, :V_x)), observations) |> async()\n",
    "\n",
    "action, subscription = subscribe!(agent, datastream);\n",
    "\n",
    "a2 = Rocket.getrecent(action) # Evoke an action from the agent\n",
    "y2 = act(world, a2) # The action influences hidden external states\n",
    "\n",
    "next!(ys, y2)\n",
    "\n",
    "println(a2, \" \", y2, \" \", Rocket.getrecent(action))\n",
    "\n",
    "animstep!(rod,y2)\n",
    "# sleep(0.01)\n",
    "\n",
    "# The run button is actually pretty simple, we'll add it below the plot\n",
    "run = Button(fig[2,1]; label = \"run\", tellwidth = false)\n",
    "stop = Button(fig[3,1]; label = \"stop\", tellwidth = false)\n",
    "# This button will start/stop an animation. It's actually surprisingly\n",
    "# simple to do this. The magic code is:\n",
    "isrunning = Observable(true)\n",
    "\n",
    "on(run.clicks) do clicks\n",
    "    isrunning[] = true\n",
    "end\n",
    "\n",
    "on(stop.clicks) do clicks\n",
    "    isrunning[] = false\n",
    "    unsubscribe!(subscription)\n",
    "end\n",
    "\n",
    "on(run.clicks) do clicks\n",
    "    @async begin \n",
    "        try \n",
    "            # println(\"asd\")\n",
    "            iters = 1\n",
    "            while isrunning[] && iters < 10\n",
    "                global y2\n",
    "                global a2\n",
    "\n",
    "                isopen(fig.scene) || break # ensures computations stop if closed window\n",
    "\n",
    "                a2 = Rocket.getrecent(action) # Evoke an action from the agent\n",
    "                y2 = act(world, a2) # The action influences hidden external states\n",
    "                next!(ys, y2) \n",
    "                animstep!(rod,y2)\n",
    "                sleep(0.01)\n",
    "            end\n",
    "        catch err\n",
    "            bt = catch_backtrace()\n",
    "            println()\n",
    "            showerror(stderr, err, bt)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "# on(ax.scene.events.mousebutton) do mpos\n",
    "#     #global a2\n",
    "#     global y2\n",
    "    \n",
    "#     if ispressed(ax.scene, Mouse.left)\n",
    "#        pos = to_world(ax.scene, Point2f(ax.scene.events.mouseposition[]))\n",
    "#        #print(pos)\n",
    "#        y2 = atan(pos[2],pos[1]) + π/2 \n",
    "#        balls[] = [Point2f(pos[1]-1, pos[2]-0.5)]\n",
    "#        rod[] = [Point2f(0, 0), Point2f(pos[1]-1, pos[2]-0.5)]\n",
    "        \n",
    "#    end\n",
    "#    return\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becfc5bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fcfd5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2034130b",
   "metadata": {},
   "source": [
    "**Credits** The original code is written by Sepideh Adamiat. Adapted by Dmitry Bagaev"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.4",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
